[TRAIN] keras.Model.fit patched: epochs≥500, EarlyStopping(patience=25), ReduceLROnPlateau(patience=7), cosine=true
[ENV] {"type": "env", "ts": "2025-11-22T17:04:07+00:00", "python": "3.13.7", "platform": {"system": "Darwin", "release": "25.1.0", "machine": "arm64"}, "versions": {"numpy": "2.3.5", "pandas": "2.3.3", "scikit_learn": "1.7.2", "scipy": "1.16.3", "tensorflow": "2.20.0", "keras": "3.12.0", "xgboost": "3.1.1", "hmmlearn": "0.3.3"}}
Loaded 749 historical draws.
[REGIME] GMM fitted on 749 draws into 3 regimes.
[TRAIN] keras.Model.compile patched: {"set_loss": true, "rank_w": 0.15, "reward_w": 0.15, "tau": 0.05, "pair_neg": 20, "add_metrics": true}
[REGIME] Current regime: 1
Epoch 1/500
Chosen method: PF, Final Top-6 prediction: [9, 10, 19, 25, 35, 38]
Training Temporal CNN model...
Epoch 1/500
74/74 - 2s - 27ms/step - hits_at_6: 0.8632 - loss: 0.7653 - recall_at_6: 0.1439 - val_hits_at_6: 0.9145 - val_loss: 0.5430 - val_recall_at_6: 0.1524
Epoch 2/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8395 - loss: 0.6243 - recall_at_6: 0.1399 - val_hits_at_6: 0.9211 - val_loss: 0.5298 - val_recall_at_6: 0.1535
Epoch 3/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9155 - loss: 0.5828 - recall_at_6: 0.1526 - val_hits_at_6: 0.8618 - val_loss: 0.5282 - val_recall_at_6: 0.1436
Epoch 4/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8801 - loss: 0.5758 - recall_at_6: 0.1467 - val_hits_at_6: 0.8289 - val_loss: 0.5253 - val_recall_at_6: 0.1382
Epoch 5/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9071 - loss: 0.5677 - recall_at_6: 0.1512 - val_hits_at_6: 0.9013 - val_loss: 0.5243 - val_recall_at_6: 0.1502
Epoch 6/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9257 - loss: 0.5622 - recall_at_6: 0.1543 - val_hits_at_6: 0.8224 - val_loss: 0.5247 - val_recall_at_6: 0.1371
Epoch 7/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9037 - loss: 0.5643 - recall_at_6: 0.1506 - val_hits_at_6: 0.8487 - val_loss: 0.5242 - val_recall_at_6: 0.1414
Epoch 8/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9088 - loss: 0.5596 - recall_at_6: 0.1515 - val_hits_at_6: 0.8618 - val_loss: 0.5240 - val_recall_at_6: 0.1436
Epoch 9/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9730 - loss: 0.5603 - recall_at_6: 0.1622 - val_hits_at_6: 0.9671 - val_loss: 0.5220 - val_recall_at_6: 0.1612
Epoch 10/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9645 - loss: 0.5560 - recall_at_6: 0.1608 - val_hits_at_6: 0.9408 - val_loss: 0.5209 - val_recall_at_6: 0.1568
Epoch 11/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8851 - loss: 0.5592 - recall_at_6: 0.1475 - val_hits_at_6: 0.9408 - val_loss: 0.5239 - val_recall_at_6: 0.1568
Epoch 12/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9645 - loss: 0.5561 - recall_at_6: 0.1608 - val_hits_at_6: 0.8684 - val_loss: 0.5212 - val_recall_at_6: 0.1447
Epoch 13/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9595 - loss: 0.5548 - recall_at_6: 0.1599 - val_hits_at_6: 0.9408 - val_loss: 0.5219 - val_recall_at_6: 0.1568
Epoch 14/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9966 - loss: 0.5564 - recall_at_6: 0.1661 - val_hits_at_6: 0.8421 - val_loss: 0.5224 - val_recall_at_6: 0.1404
Epoch 15/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9426 - loss: 0.5560 - recall_at_6: 0.1571 - val_hits_at_6: 0.9803 - val_loss: 0.5208 - val_recall_at_6: 0.1634
Epoch 16/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9595 - loss: 0.5581 - recall_at_6: 0.1599 - val_hits_at_6: 0.9539 - val_loss: 0.5211 - val_recall_at_6: 0.1590
Epoch 17/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9679 - loss: 0.5529 - recall_at_6: 0.1613 - val_hits_at_6: 0.9013 - val_loss: 0.5205 - val_recall_at_6: 0.1502
Epoch 18/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9409 - loss: 0.5526 - recall_at_6: 0.1568 - val_hits_at_6: 0.9342 - val_loss: 0.5206 - val_recall_at_6: 0.1557
Epoch 19/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9527 - loss: 0.5529 - recall_at_6: 0.1588 - val_hits_at_6: 0.8947 - val_loss: 0.5210 - val_recall_at_6: 0.1491
Epoch 20/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0084 - loss: 0.5495 - recall_at_6: 0.1681 - val_hits_at_6: 0.9013 - val_loss: 0.5201 - val_recall_at_6: 0.1502
Epoch 21/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9848 - loss: 0.5560 - recall_at_6: 0.1641 - val_hits_at_6: 0.9211 - val_loss: 0.5209 - val_recall_at_6: 0.1535
Epoch 22/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0068 - loss: 0.5521 - recall_at_6: 0.1678 - val_hits_at_6: 0.8882 - val_loss: 0.5207 - val_recall_at_6: 0.1480
Epoch 23/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9797 - loss: 0.5537 - recall_at_6: 0.1633 - val_hits_at_6: 0.8553 - val_loss: 0.5209 - val_recall_at_6: 0.1425
Epoch 24/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9527 - loss: 0.5532 - recall_at_6: 0.1588 - val_hits_at_6: 0.8816 - val_loss: 0.5207 - val_recall_at_6: 0.1469
Epoch 25/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0101 - loss: 0.5511 - recall_at_6: 0.1684 - val_hits_at_6: 0.8750 - val_loss: 0.5208 - val_recall_at_6: 0.1458
Epoch 26/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0389 - loss: 0.5541 - recall_at_6: 0.1731 - val_hits_at_6: 0.8684 - val_loss: 0.5209 - val_recall_at_6: 0.1447
Epoch 27/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0236 - loss: 0.5508 - recall_at_6: 0.1706 - val_hits_at_6: 0.8684 - val_loss: 0.5209 - val_recall_at_6: 0.1447
Epoch 28/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0017 - loss: 0.5487 - recall_at_6: 0.1669 - val_hits_at_6: 0.9276 - val_loss: 0.5177 - val_recall_at_6: 0.1546
Epoch 29/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0270 - loss: 0.5520 - recall_at_6: 0.1712 - val_hits_at_6: 1.0461 - val_loss: 0.5225 - val_recall_at_6: 0.1743
Epoch 30/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9696 - loss: 0.5513 - recall_at_6: 0.1616 - val_hits_at_6: 0.8421 - val_loss: 0.5200 - val_recall_at_6: 0.1404
Epoch 31/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9730 - loss: 0.5510 - recall_at_6: 0.1622 - val_hits_at_6: 0.9211 - val_loss: 0.5201 - val_recall_at_6: 0.1535
Epoch 32/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9426 - loss: 0.5539 - recall_at_6: 0.1571 - val_hits_at_6: 0.9342 - val_loss: 0.5210 - val_recall_at_6: 0.1557
Epoch 33/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9814 - loss: 0.5492 - recall_at_6: 0.1636 - val_hits_at_6: 0.9276 - val_loss: 0.5212 - val_recall_at_6: 0.1546
Epoch 34/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9324 - loss: 0.5529 - recall_at_6: 0.1554 - val_hits_at_6: 1.0000 - val_loss: 0.5185 - val_recall_at_6: 0.1667
Epoch 35/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0051 - loss: 0.5497 - recall_at_6: 0.1675 - val_hits_at_6: 0.9211 - val_loss: 0.5211 - val_recall_at_6: 0.1535
Epoch 36/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0625 - loss: 0.5468 - recall_at_6: 0.1771 - val_hits_at_6: 1.0000 - val_loss: 0.5216 - val_recall_at_6: 0.1667
Epoch 37/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0101 - loss: 0.5500 - recall_at_6: 0.1684 - val_hits_at_6: 0.9934 - val_loss: 0.5210 - val_recall_at_6: 0.1656
Epoch 38/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0355 - loss: 0.5463 - recall_at_6: 0.1726 - val_hits_at_6: 0.9079 - val_loss: 0.5178 - val_recall_at_6: 0.1513
Epoch 39/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0693 - loss: 0.5449 - recall_at_6: 0.1782 - val_hits_at_6: 0.9145 - val_loss: 0.5200 - val_recall_at_6: 0.1524
Epoch 40/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0878 - loss: 0.5445 - recall_at_6: 0.1813 - val_hits_at_6: 1.0000 - val_loss: 0.5190 - val_recall_at_6: 0.1667
Epoch 41/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0338 - loss: 0.5471 - recall_at_6: 0.1723 - val_hits_at_6: 1.0263 - val_loss: 0.5198 - val_recall_at_6: 0.1711
Epoch 42/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9899 - loss: 0.5479 - recall_at_6: 0.1650 - val_hits_at_6: 1.0066 - val_loss: 0.5186 - val_recall_at_6: 0.1678
Epoch 43/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0625 - loss: 0.5447 - recall_at_6: 0.1771 - val_hits_at_6: 0.9605 - val_loss: 0.5202 - val_recall_at_6: 0.1601
Epoch 44/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0777 - loss: 0.5441 - recall_at_6: 0.1796 - val_hits_at_6: 0.9474 - val_loss: 0.5174 - val_recall_at_6: 0.1579
Epoch 45/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0794 - loss: 0.5443 - recall_at_6: 0.1799 - val_hits_at_6: 0.9605 - val_loss: 0.5196 - val_recall_at_6: 0.1601
Epoch 46/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0541 - loss: 0.5439 - recall_at_6: 0.1757 - val_hits_at_6: 0.9737 - val_loss: 0.5184 - val_recall_at_6: 0.1623
Epoch 47/500
74/74 - 0s - 2ms/step - hits_at_6: 1.1402 - loss: 0.5402 - recall_at_6: 0.1900 - val_hits_at_6: 0.9737 - val_loss: 0.5204 - val_recall_at_6: 0.1623
Epoch 48/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0963 - loss: 0.5415 - recall_at_6: 0.1827 - val_hits_at_6: 0.9868 - val_loss: 0.5200 - val_recall_at_6: 0.1645
Epoch 49/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0203 - loss: 0.5436 - recall_at_6: 0.1700 - val_hits_at_6: 0.9737 - val_loss: 0.5199 - val_recall_at_6: 0.1623
Epoch 50/500
74/74 - 0s - 2ms/step - hits_at_6: 1.1182 - loss: 0.5408 - recall_at_6: 0.1864 - val_hits_at_6: 0.9276 - val_loss: 0.5192 - val_recall_at_6: 0.1546
Epoch 51/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0490 - loss: 0.5411 - recall_at_6: 0.1748 - val_hits_at_6: 0.9605 - val_loss: 0.5196 - val_recall_at_6: 0.1601
Epoch 52/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0743 - loss: 0.5421 - recall_at_6: 0.1791 - val_hits_at_6: 0.9671 - val_loss: 0.5191 - val_recall_at_6: 0.1612
Epoch 53/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0912 - loss: 0.5391 - recall_at_6: 0.1819 - val_hits_at_6: 0.9474 - val_loss: 0.5208 - val_recall_at_6: 0.1579
Epoch 54/500
74/74 - 0s - 2ms/step - hits_at_6: 1.1250 - loss: 0.5399 - recall_at_6: 0.1875 - val_hits_at_6: 0.9803 - val_loss: 0.5205 - val_recall_at_6: 0.1634
Epoch 55/500
74/74 - 0s - 2ms/step - hits_at_6: 1.1875 - loss: 0.5388 - recall_at_6: 0.1979 - val_hits_at_6: 0.9671 - val_loss: 0.5193 - val_recall_at_6: 0.1612
Epoch 56/500
74/74 - 0s - 2ms/step - hits_at_6: 1.1791 - loss: 0.5369 - recall_at_6: 0.1965 - val_hits_at_6: 0.9737 - val_loss: 0.5185 - val_recall_at_6: 0.1623
Epoch 57/500
74/74 - 0s - 2ms/step - hits_at_6: 1.1892 - loss: 0.5379 - recall_at_6: 0.1982 - val_hits_at_6: 0.9803 - val_loss: 0.5196 - val_recall_at_6: 0.1634
Epoch 58/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0861 - loss: 0.5376 - recall_at_6: 0.1810 - val_hits_at_6: 0.9605 - val_loss: 0.5201 - val_recall_at_6: 0.1601
Epoch 59/500
74/74 - 0s - 2ms/step - hits_at_6: 1.0743 - loss: 0.5378 - recall_at_6: 0.1791 - val_hits_at_6: 0.9868 - val_loss: 0.5214 - val_recall_at_6: 0.1645
Epoch 60/500
74/74 - 0s - 2ms/step - hits_at_6: 1.1689 - loss: 0.5356 - recall_at_6: 0.1948 - val_hits_at_6: 0.9671 - val_loss: 0.5200 - val_recall_at_6: 0.1612
Epoch 61/500
74/74 - 0s - 2ms/step - hits_at_6: 1.1588 - loss: 0.5380 - recall_at_6: 0.1931 - val_hits_at_6: 1.0066 - val_loss: 0.5209 - val_recall_at_6: 0.1678
Epoch 62/500
74/74 - 0s - 2ms/step - hits_at_6: 1.1284 - loss: 0.5380 - recall_at_6: 0.1881 - val_hits_at_6: 1.0000 - val_loss: 0.5197 - val_recall_at_6: 0.1667
Epoch 63/500
74/74 - 0s - 2ms/step - hits_at_6: 1.2601 - loss: 0.5319 - recall_at_6: 0.2100 - val_hits_at_6: 1.0329 - val_loss: 0.5207 - val_recall_at_6: 0.1721
Epoch 64/500
74/74 - 0s - 2ms/step - hits_at_6: 1.1875 - loss: 0.5344 - recall_at_6: 0.1979 - val_hits_at_6: 1.0263 - val_loss: 0.5204 - val_recall_at_6: 0.1711
Training Transformer model...
Epoch 1/1000
74/74 - 3s - 46ms/step - hits_at_6: 0.8007 - loss: 2.4551 - recall_at_6: 0.1334 - val_hits_at_6: 1.0197 - val_loss: 2.4177 - val_recall_at_6: 0.1700
Epoch 2/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.9392 - loss: 2.4177 - recall_at_6: 0.1565 - val_hits_at_6: 1.0197 - val_loss: 2.4177 - val_recall_at_6: 0.1700
Epoch 3/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.8733 - loss: 2.4187 - recall_at_6: 0.1456 - val_hits_at_6: 1.0132 - val_loss: 2.4177 - val_recall_at_6: 0.1689
Epoch 4/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.8581 - loss: 2.4177 - recall_at_6: 0.1430 - val_hits_at_6: 1.0066 - val_loss: 2.4177 - val_recall_at_6: 0.1678
Epoch 5/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.9037 - loss: 2.4177 - recall_at_6: 0.1506 - val_hits_at_6: 1.0066 - val_loss: 2.4177 - val_recall_at_6: 0.1678
Epoch 6/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.8953 - loss: 2.4177 - recall_at_6: 0.1492 - val_hits_at_6: 0.9803 - val_loss: 2.4177 - val_recall_at_6: 0.1634
Epoch 7/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.8885 - loss: 2.4177 - recall_at_6: 0.1481 - val_hits_at_6: 0.9737 - val_loss: 2.4177 - val_recall_at_6: 0.1623
Epoch 8/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.8953 - loss: 2.4177 - recall_at_6: 0.1492 - val_hits_at_6: 0.9737 - val_loss: 2.4177 - val_recall_at_6: 0.1623
Epoch 9/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.8986 - loss: 2.4177 - recall_at_6: 0.1498 - val_hits_at_6: 0.9737 - val_loss: 2.4177 - val_recall_at_6: 0.1623
Epoch 10/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.9003 - loss: 2.4177 - recall_at_6: 0.1501 - val_hits_at_6: 0.9737 - val_loss: 2.4177 - val_recall_at_6: 0.1623
Epoch 11/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.8497 - loss: 2.4177 - recall_at_6: 0.1416 - val_hits_at_6: 0.9737 - val_loss: 2.4177 - val_recall_at_6: 0.1623
Epoch 12/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.8953 - loss: 2.4177 - recall_at_6: 0.1492 - val_hits_at_6: 0.9737 - val_loss: 2.4177 - val_recall_at_6: 0.1623
Epoch 13/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.9003 - loss: 2.4177 - recall_at_6: 0.1501 - val_hits_at_6: 0.9737 - val_loss: 2.4177 - val_recall_at_6: 0.1623
Epoch 14/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.9274 - loss: 2.4175 - recall_at_6: 0.1546 - val_hits_at_6: 0.8816 - val_loss: 2.4177 - val_recall_at_6: 0.1469
Epoch 15/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.9409 - loss: 2.4213 - recall_at_6: 0.1568 - val_hits_at_6: 0.9211 - val_loss: 2.4177 - val_recall_at_6: 0.1535
Epoch 16/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.8733 - loss: 2.4188 - recall_at_6: 0.1456 - val_hits_at_6: 0.9605 - val_loss: 2.4177 - val_recall_at_6: 0.1601
Epoch 17/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.8547 - loss: 2.4166 - recall_at_6: 0.1425 - val_hits_at_6: 0.9671 - val_loss: 2.4177 - val_recall_at_6: 0.1612
Epoch 18/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.8919 - loss: 2.4185 - recall_at_6: 0.1486 - val_hits_at_6: 0.9539 - val_loss: 2.4177 - val_recall_at_6: 0.1590
Epoch 19/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.8615 - loss: 2.4173 - recall_at_6: 0.1436 - val_hits_at_6: 0.9408 - val_loss: 2.4177 - val_recall_at_6: 0.1568
Epoch 20/1000
74/74 - 0s - 4ms/step - hits_at_6: 0.9645 - loss: 2.4178 - recall_at_6: 0.1608 - val_hits_at_6: 0.9605 - val_loss: 2.4177 - val_recall_at_6: 0.1601
Training GNN model...
Epoch 1/500
74/74 - 2s - 31ms/step - hits_at_6: 0.8260 - loss: 2.3064 - recall_at_6: 0.1377 - val_hits_at_6: 0.9079 - val_loss: 2.4159 - val_recall_at_6: 0.1513
Epoch 2/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9510 - loss: 1.9774 - recall_at_6: 0.1585 - val_hits_at_6: 0.8289 - val_loss: 0.7408 - val_recall_at_6: 0.1382
Epoch 3/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9105 - loss: 1.3239 - recall_at_6: 0.1517 - val_hits_at_6: 0.8026 - val_loss: 0.6664 - val_recall_at_6: 0.1338
Epoch 4/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8176 - loss: 1.0500 - recall_at_6: 0.1363 - val_hits_at_6: 0.8421 - val_loss: 0.5582 - val_recall_at_6: 0.1404
Epoch 5/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9223 - loss: 0.8655 - recall_at_6: 0.1537 - val_hits_at_6: 0.8553 - val_loss: 0.5517 - val_recall_at_6: 0.1425
Epoch 6/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8868 - loss: 0.8031 - recall_at_6: 0.1478 - val_hits_at_6: 0.8947 - val_loss: 0.5551 - val_recall_at_6: 0.1491
Epoch 7/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9679 - loss: 0.7605 - recall_at_6: 0.1613 - val_hits_at_6: 0.8618 - val_loss: 0.5334 - val_recall_at_6: 0.1436
Epoch 8/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8328 - loss: 0.7431 - recall_at_6: 0.1388 - val_hits_at_6: 0.8750 - val_loss: 0.5313 - val_recall_at_6: 0.1458
Epoch 9/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9054 - loss: 0.7172 - recall_at_6: 0.1509 - val_hits_at_6: 0.8553 - val_loss: 0.5269 - val_recall_at_6: 0.1425
Epoch 10/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8716 - loss: 0.6968 - recall_at_6: 0.1453 - val_hits_at_6: 0.9474 - val_loss: 0.5368 - val_recall_at_6: 0.1579
Epoch 11/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8682 - loss: 0.6777 - recall_at_6: 0.1447 - val_hits_at_6: 1.0263 - val_loss: 0.5422 - val_recall_at_6: 0.1711
Epoch 12/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9358 - loss: 0.6511 - recall_at_6: 0.1560 - val_hits_at_6: 0.9868 - val_loss: 0.5422 - val_recall_at_6: 0.1645
Epoch 13/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9088 - loss: 0.6564 - recall_at_6: 0.1515 - val_hits_at_6: 0.9474 - val_loss: 0.5412 - val_recall_at_6: 0.1579
Epoch 14/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9206 - loss: 0.6518 - recall_at_6: 0.1534 - val_hits_at_6: 1.0132 - val_loss: 0.5394 - val_recall_at_6: 0.1689
Epoch 15/500
74/74 - 0s - 2ms/step - hits_at_6: 0.9443 - loss: 0.6363 - recall_at_6: 0.1574 - val_hits_at_6: 0.9868 - val_loss: 0.5370 - val_recall_at_6: 0.1645
Epoch 16/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8598 - loss: 0.6456 - recall_at_6: 0.1433 - val_hits_at_6: 0.9803 - val_loss: 0.5363 - val_recall_at_6: 0.1634
Epoch 17/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8615 - loss: 0.6455 - recall_at_6: 0.1436 - val_hits_at_6: 0.9803 - val_loss: 0.5345 - val_recall_at_6: 0.1634
Epoch 18/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8936 - loss: 0.6378 - recall_at_6: 0.1489 - val_hits_at_6: 0.9868 - val_loss: 0.5334 - val_recall_at_6: 0.1645
Epoch 19/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8936 - loss: 0.6353 - recall_at_6: 0.1489 - val_hits_at_6: 0.9934 - val_loss: 0.5323 - val_recall_at_6: 0.1656
Epoch 20/500
74/74 - 0s - 2ms/step - hits_at_6: 0.8682 - loss: 0.6346 - recall_at_6: 0.1447 - val_hits_at_6: 0.9868 - val_loss: 0.5320 - val_recall_at_6: 0.1645
/Users/coleoehlrich/Colorado_Lotto/Lotto+.py:8429: UserWarning: Ensemble computation failed: Inputs to a layer should be tensors. Got 'None' (of type <class 'NoneType'>) as input for layer 'functional_4'.
  warnings.warn(f"Ensemble computation failed: {e}")
GNN model training complete.
[OPT] GP-tuned knobs: {}
[RUN] {"type": "predict_log", "ts": "2025-11-22T17:25:37+00:00", "hmmlearn": "0.3.3", "blend_weights": [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], "calibration": null, "per_expert_pl_nll": {"Bayes": 22.243783307645153, "Markov": 22.398137204325128, "HMM": 22.37458061356002, "LSTM": 22.152764466961372, "Transformer": 24.77800734971048, "GNN": 22.08684437072085}, "weekday_gate": null, "feedback": {"window": 90, "t_fit": 748, "brier": 0.1431215855655981, "logloss": 0.5751281453347421}}
[MISS t=599] hits=1 top6=[4, 8, 30, 3, 6, 33] truth=[4, 14, 18, 25, 32, 38] low_truth=[32, 25] overconf=[8, 30]
[MISS t=600] hits=0 top6=[4, 38, 18, 30, 14, 25] truth=[3, 11, 17, 22, 23, 36] low_truth=[36, 22] overconf=[4, 38]
[MISS t=601] hits=0 top6=[3, 4, 25, 23, 38, 11] truth=[10, 14, 19, 28, 36, 39] low_truth=[39, 14] overconf=[3, 4]
[MISS t=602] hits=0 top6=[36, 4, 19, 3, 11, 10] truth=[9, 14, 28, 29, 30, 38] low_truth=[9, 29] overconf=[36, 4]
[MISS t=603] hits=1 top6=[14, 30, 4, 38, 3, 23] truth=[6, 10, 26, 30, 34, 36] low_truth=[34, 26] overconf=[14, 4]
[MISS t=604] hits=1 top6=[30, 10, 4, 6, 38, 40] truth=[7, 10, 11, 18, 19, 31] low_truth=[31, 7] overconf=[30, 4]
[MISS t=606] hits=1 top6=[6, 10, 30, 35, 25, 4] truth=[13, 14, 24, 25, 27, 34] low_truth=[24, 13] overconf=[6, 10]
[MISS t=607] hits=0 top6=[14, 10, 30, 34, 4, 6] truth=[12, 17, 19, 26, 28, 36] low_truth=[36, 12] overconf=[14, 10]
[MISS t=608] hits=1 top6=[17, 19, 28, 13, 10, 30] truth=[1, 2, 13, 31, 36, 37] low_truth=[1, 31] overconf=[17, 19]
[MISS t=609] hits=1 top6=[31, 13, 30, 10, 36, 19] truth=[2, 3, 14, 25, 28, 36] low_truth=[2, 25] overconf=[31, 13]
[MISS t=611] hits=0 top6=[28, 36, 14, 30, 10, 3] truth=[12, 19, 21, 37, 38, 40] low_truth=[12, 37] overconf=[28, 36]
[MISS t=612] hits=1 top6=[19, 38, 14, 30, 36, 10] truth=[5, 11, 15, 26, 35, 36] low_truth=[5, 35] overconf=[19, 38]
[MISS t=613] hits=1 top6=[36, 30, 28, 10, 33, 40] truth=[1, 18, 24, 28, 31, 34] low_truth=[24, 34] overconf=[36, 30]
[MISS t=615] hits=0 top6=[31, 14, 6, 36, 26, 10] truth=[7, 23, 24, 27, 33, 34] low_truth=[7, 34] overconf=[31, 14]
[MISS t=616] hits=0 top6=[24, 14, 34, 28, 36, 4] truth=[5, 9, 21, 25, 35, 39] low_truth=[5, 35] overconf=[24, 14]
[MISS t=617] hits=1 top6=[5, 36, 27, 14, 35, 28] truth=[2, 13, 14, 16, 21, 25] low_truth=[13, 2] overconf=[5, 36]
[MISS t=618] hits=1 top6=[25, 21, 14, 27, 35, 36] truth=[7, 8, 14, 30, 37, 40] low_truth=[7, 40] overconf=[25, 21]
[MISS t=619] hits=1 top6=[37, 14, 4, 25, 30, 40] truth=[7, 23, 25, 27, 32, 35] low_truth=[32, 35] overconf=[37, 14]
[MISS t=620] hits=1 top6=[25, 7, 23, 27, 14, 37] truth=[7, 17, 22, 33, 36, 40] low_truth=[22, 17] overconf=[25, 23]
[MISS t=621] hits=0 top6=[7, 33, 14, 25, 40, 36] truth=[1, 3, 8, 30, 34, 38] low_truth=[1, 8] overconf=[7, 33]
[MISS t=622] hits=1 top6=[3, 8, 30, 38, 36, 33] truth=[4, 12, 16, 26, 35, 38] low_truth=[12, 16] overconf=[3, 8]
[MISS t=623] hits=0 top6=[38, 35, 4, 28, 30, 3] truth=[10, 13, 14, 16, 27, 39] low_truth=[39, 27] overconf=[38, 35]
[MISS t=624] hits=0 top6=[14, 30, 27, 38, 16, 13] truth=[7, 18, 24, 31, 35, 40] low_truth=[18, 24] overconf=[14, 30]
[MISS t=625] hits=0 top6=[14, 35, 31, 7, 40, 24] truth=[5, 11, 20, 23, 25, 27] low_truth=[5, 20] overconf=[14, 35]
[MISS t=626] hits=1 top6=[27, 25, 35, 14, 28, 7] truth=[15, 33, 35, 37, 38, 39] low_truth=[15, 39] overconf=[27, 25]
[MISS t=627] hits=1 top6=[38, 30, 14, 7, 27, 35] truth=[14, 17, 19, 23, 24, 26] low_truth=[24, 19] overconf=[38, 30]
[MISS t=628] hits=0 top6=[14, 30, 38, 24, 26, 17] truth=[4, 8, 18, 19, 35, 37] low_truth=[18, 8] overconf=[14, 30]
[MISS t=629] hits=1 top6=[37, 35, 4, 19, 14, 23] truth=[1, 3, 23, 27, 28, 36] low_truth=[3, 1] overconf=[37, 35]
[MISS t=630] hits=1 top6=[23, 3, 36, 37, 35, 14] truth=[2, 12, 18, 25, 37, 39] low_truth=[2, 12] overconf=[23, 3]
[MISS t=631] hits=1 top6=[39, 37, 12, 18, 23, 25] truth=[4, 12, 21, 22, 33, 40] low_truth=[22, 40] overconf=[39, 37]
[MISS t=633] hits=0 top6=[14, 37, 12, 33, 30, 4] truth=[5, 9, 16, 17, 32, 38] low_truth=[5, 32] overconf=[14, 37]
[MISS t=634] hits=1 top6=[9, 14, 33, 38, 17, 37] truth=[9, 16, 18, 22, 25, 31] low_truth=[22, 16] overconf=[14, 33]
[MISS t=635] hits=1 top6=[18, 16, 25, 9, 37, 31] truth=[18, 20, 22, 27, 30, 32] low_truth=[20, 32] overconf=[16, 25]
[MISS t=638] hits=0 top6=[18, 25, 14, 27, 33, 40] truth=[8, 10, 11, 12, 13, 31] low_truth=[11, 31] overconf=[18, 25]
[MISS t=639] hits=1 top6=[25, 31, 14, 18, 28, 4] truth=[2, 8, 9, 14, 19, 36] low_truth=[2, 9] overconf=[25, 31]
[MISS t=640] hits=1 top6=[14, 18, 36, 27, 19, 25] truth=[11, 27, 28, 30, 33, 40] low_truth=[11, 28] overconf=[14, 18]
[MISS t=641] hits=1 top6=[11, 30, 18, 40, 27, 33] truth=[2, 3, 9, 23, 27, 34] low_truth=[34, 3] overconf=[11, 30]
[MISS t=645] hits=1 top6=[14, 27, 9, 3, 33, 31] truth=[8, 15, 21, 31, 37, 39] low_truth=[39, 8] overconf=[14, 27]
[MISS t=646] hits=1 top6=[31, 15, 9, 37, 18, 27] truth=[1, 10, 20, 25, 37, 38] low_truth=[1, 20] overconf=[31, 15]
[MISS t=647] hits=0 top6=[37, 25, 31, 14, 27, 23] truth=[1, 4, 13, 28, 32, 36] low_truth=[13, 4] overconf=[37, 25]
[MISS t=648] hits=0 top6=[1, 32, 9, 36, 14, 37] truth=[4, 11, 22, 30, 34, 35] low_truth=[34, 22] overconf=[1, 32]
[MISS t=653] hits=0 top6=[9, 30, 27, 3, 14, 5] truth=[4, 7, 16, 18, 21, 36] low_truth=[21, 16] overconf=[9, 30]
[MISS t=654] hits=0 top6=[4, 36, 27, 18, 9, 3] truth=[5, 8, 11, 16, 23, 24] low_truth=[24, 5] overconf=[4, 36]
[MISS t=655] hits=1 top6=[9, 4, 5, 8, 18, 30] truth=[6, 10, 25, 29, 30, 38] low_truth=[6, 29] overconf=[9, 4]
[MISS t=656] hits=1 top6=[25, 30, 11, 4, 36, 3] truth=[19, 25, 26, 32, 37, 40] low_truth=[32, 26] overconf=[30, 11]
[MISS t=657] hits=1 top6=[19, 25, 30, 3, 14, 4] truth=[7, 9, 17, 21, 26, 30] low_truth=[7, 21] overconf=[19, 25]
[MISS t=658] hits=0 top6=[30, 9, 26, 4, 25, 12] truth=[11, 14, 15, 18, 27, 37] low_truth=[15, 11] overconf=[30, 9]
[MISS t=659] hits=1 top6=[11, 37, 27, 18, 30, 9] truth=[1, 6, 25, 27, 28, 38] low_truth=[1, 6] overconf=[11, 37]
[MISS t=660] hits=0 top6=[27, 14, 25, 9, 30, 11] truth=[12, 16, 20, 29, 33, 38] low_truth=[29, 12] overconf=[27, 14]
[MISS t=661] hits=0 top6=[29, 27, 25, 9, 3, 4] truth=[19, 23, 31, 34, 35, 38] low_truth=[31, 35] overconf=[29, 27]
[MISS t=662] hits=1 top6=[38, 23, 36, 27, 9, 19] truth=[5, 6, 15, 37, 38, 40] low_truth=[15, 40] overconf=[23, 36]
[MISS t=663] hits=1 top6=[37, 38, 4, 27, 30, 40] truth=[17, 18, 19, 25, 27, 28] low_truth=[17, 19] overconf=[37, 38]
[MISS t=665] hits=1 top6=[38, 9, 27, 29, 25, 11] truth=[2, 15, 17, 29, 34, 39] low_truth=[39, 34] overconf=[38, 9]
[MISS t=666] hits=0 top6=[9, 38, 17, 27, 29, 15] truth=[8, 14, 19, 24, 36, 37] low_truth=[24, 8] overconf=[9, 38]
[MISS t=667] hits=0 top6=[37, 19, 14, 27, 17, 38] truth=[5, 7, 11, 12, 22, 28] low_truth=[22, 12] overconf=[37, 19]
[MISS t=669] hits=1 top6=[37, 5, 4, 18, 8, 14] truth=[2, 8, 20, 24, 29, 32] low_truth=[32, 2] overconf=[37, 5]
[MISS t=670] hits=1 top6=[8, 2, 29, 9, 5, 14] truth=[7, 17, 19, 27, 29, 36] low_truth=[7, 19] overconf=[8, 2]
[MISS t=671] hits=1 top6=[29, 27, 19, 14, 17, 9] truth=[5, 8, 15, 27, 35, 38] low_truth=[35, 8] overconf=[29, 19]
[MISS t=672] hits=0 top6=[5, 27, 8, 29, 38, 35] truth=[1, 2, 12, 13, 22, 32] low_truth=[12, 13] overconf=[5, 27]
[MISS t=673] hits=0 top6=[29, 27, 37, 40, 8, 30] truth=[6, 10, 22, 28, 31, 35] low_truth=[31, 6] overconf=[29, 27]
[MISS t=674] hits=1 top6=[22, 27, 35, 29, 6, 8] truth=[3, 5, 12, 21, 24, 29] low_truth=[12, 21] overconf=[22, 27]
[MISS t=678] hits=1 top6=[5, 27, 12, 4, 15, 25] truth=[2, 7, 21, 27, 28, 40] low_truth=[7, 2] overconf=[5, 12]
[MISS t=679] hits=0 top6=[5, 27, 21, 4, 16, 2] truth=[14, 24, 30, 33, 36, 38] low_truth=[24, 33] overconf=[5, 27]
[MISS t=680] hits=0 top6=[5, 38, 33, 14, 29, 27] truth=[2, 4, 8, 18, 20, 26] low_truth=[26, 20] overconf=[5, 38]
[MISS t=681] hits=1 top6=[2, 5, 18, 30, 27, 8] truth=[1, 8, 15, 23, 34, 37] low_truth=[1, 23] overconf=[2, 5]
[MISS t=682] hits=1 top6=[8, 18, 5, 37, 38, 15] truth=[1, 10, 15, 16, 33, 34] low_truth=[16, 34] overconf=[8, 18]
[MISS t=683] hits=1 top6=[15, 1, 9, 27, 8, 34] truth=[4, 6, 9, 13, 14, 29] low_truth=[6, 13] overconf=[15, 1]
[MISS t=685] hits=0 top6=[6, 23, 33, 8, 38, 15] truth=[4, 9, 18, 21, 36, 37] low_truth=[21, 9] overconf=[6, 23]
[MISS t=687] hits=1 top6=[29, 37, 4, 5, 33, 19] truth=[9, 11, 18, 19, 38, 39] low_truth=[39, 11] overconf=[29, 37]
[MISS t=688] hits=1 top6=[18, 9, 14, 5, 38, 15] truth=[7, 8, 16, 18, 22, 32] low_truth=[16, 22] overconf=[9, 14]
[MISS t=689] hits=1 top6=[18, 29, 9, 37, 5, 19] truth=[8, 19, 24, 33, 35, 40] low_truth=[24, 40] overconf=[18, 29]
[MISS t=690] hits=1 top6=[18, 9, 8, 19, 33, 38] truth=[14, 17, 19, 22, 29, 39] low_truth=[17, 39] overconf=[18, 9]
[MISS t=691] hits=0 top6=[19, 29, 14, 8, 18, 4] truth=[3, 9, 10, 12, 27, 38] low_truth=[3, 12] overconf=[19, 29]
[MISS t=693] hits=1 top6=[19, 35, 8, 38, 33, 29] truth=[5, 8, 14, 25, 32, 37] low_truth=[32, 5] overconf=[19, 35]
[MISS t=694] hits=0 top6=[8, 5, 37, 14, 19, 4] truth=[15, 24, 26, 32, 38, 39] low_truth=[39, 24] overconf=[8, 5]
[MISS t=695] hits=1 top6=[15, 32, 19, 8, 16, 21] truth=[5, 16, 27, 29, 33, 40] low_truth=[40, 29] overconf=[15, 32]
[MISS t=698] hits=1 top6=[27, 5, 40, 18, 19, 38] truth=[7, 8, 16, 19, 31, 35] low_truth=[31, 7] overconf=[27, 5]
[MISS t=699] hits=1 top6=[8, 16, 14, 38, 19, 27] truth=[1, 6, 15, 25, 35, 38] low_truth=[6, 1] overconf=[8, 16]
[MISS t=700] hits=1 top6=[38, 15, 27, 25, 35, 16] truth=[17, 21, 25, 29, 31, 39] low_truth=[39, 21] overconf=[38, 15]
[MISS t=701] hits=0 top6=[31, 27, 29, 40, 38, 8] truth=[9, 12, 14, 21, 24, 30] low_truth=[24, 21] overconf=[31, 27]
[MISS t=702] hits=0 top6=[38, 14, 36, 9, 33, 24] truth=[6, 11, 17, 18, 23, 32] low_truth=[23, 11] overconf=[38, 14]
[MISS t=703] hits=0 top6=[4, 18, 28, 27, 9, 25] truth=[7, 17, 23, 29, 34, 36] low_truth=[7, 34] overconf=[4, 18]
[MISS t=704] hits=1 top6=[29, 7, 23, 38, 8, 40] truth=[6, 14, 22, 32, 38, 39] low_truth=[39, 32] overconf=[29, 7]
[MISS t=705] hits=0 top6=[3, 6, 39, 33, 38, 18] truth=[14, 30, 31, 34, 35, 36] low_truth=[31, 36] overconf=[3, 6]
[MISS t=706] hits=1 top6=[38, 8, 33, 14, 20, 6] truth=[2, 4, 22, 29, 38, 39] low_truth=[39, 22] overconf=[8, 33]
[MISS t=707] hits=0 top6=[29, 39, 38, 32, 2, 4] truth=[7, 8, 19, 20, 30, 35] low_truth=[20, 7] overconf=[29, 39]
[MISS t=708] hits=1 top6=[35, 38, 39, 30, 14, 29] truth=[8, 10, 15, 16, 28, 30] low_truth=[15, 10] overconf=[35, 38]
[MISS t=709] hits=1 top6=[30, 8, 38, 28, 37, 18] truth=[13, 23, 31, 33, 35, 37] low_truth=[31, 13] overconf=[30, 8]
[MISS t=710] hits=0 top6=[35, 38, 29, 8, 23, 40] truth=[1, 3, 4, 11, 22, 27] low_truth=[1, 3] overconf=[35, 38]
[MISS t=711] hits=1 top6=[38, 4, 27, 14, 34, 35] truth=[8, 9, 11, 21, 28, 38] low_truth=[28, 21] overconf=[4, 27]
[MISS t=712] hits=1 top6=[35, 38, 8, 28, 30, 29] truth=[1, 12, 24, 33, 35, 36] low_truth=[12, 1] overconf=[38, 8]
[MISS t=713] hits=1 top6=[35, 33, 1, 5, 40, 8] truth=[2, 14, 16, 23, 29, 40] low_truth=[2, 16] overconf=[35, 33]
[MISS t=715] hits=1 top6=[33, 22, 38, 4, 27, 14] truth=[5, 13, 21, 25, 30, 33] low_truth=[13, 25] overconf=[22, 38]
[MISS t=717] hits=1 top6=[33, 1, 40, 14, 29, 35] truth=[1, 2, 16, 20, 38, 39] low_truth=[20, 2] overconf=[33, 40]
[MISS t=718] hits=1 top6=[16, 33, 29, 38, 20, 30] truth=[5, 8, 12, 16, 32, 36] low_truth=[32, 12] overconf=[33, 29]
[MISS t=719] hits=0 top6=[5, 36, 33, 32, 38, 8] truth=[4, 15, 16, 17, 30, 35] low_truth=[17, 15] overconf=[5, 36]
[MISS t=720] hits=0 top6=[30, 16, 35, 14, 33, 5] truth=[1, 6, 9, 18, 37, 38] low_truth=[6, 37] overconf=[30, 16]
[MISS t=721] hits=1 top6=[1, 38, 16, 6, 9, 30] truth=[1, 11, 12, 13, 26, 40] low_truth=[26, 13] overconf=[38, 16]
[MISS t=723] hits=0 top6=[38, 29, 17, 21, 16, 1] truth=[2, 8, 18, 19, 28, 39] low_truth=[18, 19] overconf=[38, 29]
[MISS t=724] hits=1 top6=[39, 8, 1, 33, 2, 38] truth=[3, 12, 14, 26, 33, 34] low_truth=[34, 26] overconf=[39, 8]
[MISS t=725] hits=0 top6=[12, 14, 3, 33, 26, 8] truth=[4, 5, 10, 24, 27, 37] low_truth=[24, 27] overconf=[12, 14]
[MISS t=726] hits=1 top6=[37, 4, 27, 5, 14, 38] truth=[13, 15, 21, 34, 35, 37] low_truth=[15, 21] overconf=[4, 27]
[MISS t=727] hits=1 top6=[15, 13, 37, 21, 26, 38] truth=[8, 10, 12, 28, 34, 37] low_truth=[10, 28] overconf=[15, 13]
[MISS t=728] hits=1 top6=[37, 8, 12, 33, 38, 28] truth=[7, 15, 17, 28, 30, 31] low_truth=[17, 15] overconf=[37, 8]
[MISS t=729] hits=0 top6=[28, 8, 37, 1, 30, 38] truth=[5, 7, 16, 29, 33, 34] low_truth=[5, 7] overconf=[28, 8]
[MISS t=730] hits=1 top6=[34, 7, 12, 33, 38, 8] truth=[4, 7, 11, 21, 28, 39] low_truth=[11, 28] overconf=[34, 12]
[MISS t=731] hits=0 top6=[21, 28, 33, 4, 7, 11] truth=[2, 5, 8, 14, 29, 40] low_truth=[2, 14] overconf=[21, 28]
[MISS t=732] hits=1 top6=[33, 5, 29, 14, 8, 37] truth=[5, 7, 9, 19, 20, 39] low_truth=[19, 20] overconf=[33, 29]
[MISS t=733] hits=1 top6=[7, 5, 38, 39, 29, 9] truth=[2, 7, 10, 14, 15, 21] low_truth=[15, 2] overconf=[5, 38]
[MISS t=734] hits=0 top6=[7, 21, 2, 39, 14, 33] truth=[4, 15, 16, 22, 29, 31] low_truth=[22, 31] overconf=[7, 21]
[MISS t=735] hits=0 top6=[29, 14, 31, 4, 38, 15] truth=[2, 10, 19, 25, 28, 35] low_truth=[25, 35] overconf=[29, 14]
[MISS t=736] hits=1 top6=[19, 2, 15, 28, 21, 38] truth=[1, 5, 11, 14, 28, 32] low_truth=[32, 1] overconf=[19, 2]
[MISS t=738] hits=1 top6=[19, 25, 28, 5, 38, 14] truth=[7, 12, 22, 32, 35, 38] low_truth=[22, 32] overconf=[19, 25]
[MISS t=739] hits=1 top6=[7, 14, 5, 4, 10, 19] truth=[2, 5, 6, 8, 15, 29] low_truth=[6, 8] overconf=[7, 14]
[MISS t=740] hits=1 top6=[29, 15, 5, 2, 38, 35] truth=[5, 16, 17, 25, 34, 39] low_truth=[34, 25] overconf=[29, 15]
[MISS t=741] hits=0 top6=[5, 27, 2, 29, 14, 16] truth=[9, 15, 21, 36, 37, 40] low_truth=[36, 40] overconf=[5, 27]
[MISS t=742] hits=1 top6=[5, 37, 36, 15, 16, 14] truth=[8, 11, 19, 21, 35, 37] low_truth=[11, 35] overconf=[5, 36]
[MISS t=744] hits=0 top6=[15, 11, 5, 19, 8, 37] truth=[7, 18, 20, 21, 25, 27] low_truth=[27, 25] overconf=[15, 11]
[MISS t=745] hits=1 top6=[15, 21, 5, 8, 38, 7] truth=[9, 15, 19, 25, 30, 35] low_truth=[9, 35] overconf=[21, 5]
[MISS t=746] hits=0 top6=[15, 19, 9, 30, 8, 5] truth=[6, 11, 14, 18, 23, 36] low_truth=[36, 23] overconf=[15, 19]
[MISS t=747] hits=1 top6=[11, 36, 15, 14, 21, 35] truth=[3, 6, 20, 28, 35, 37] low_truth=[3, 20] overconf=[11, 36]
[MISS t=748] hits=0 top6=[35, 37, 25, 28, 15, 14] truth=[2, 7, 10, 38, 39, 40] low_truth=[39, 2] overconf=[35, 37]
[DIAG] Backtest summary: {'mean_nll': 22.150967763947452, 'mean_hits_top6': 0.9333333333333333, 'n_draws': 150}
[DIAG] Oracle ablation mean ΔNLL: {'Bayes': 4.781755661223833, 'Markov': 4.763810257848585, 'HMM': 4.3770083278771486, 'LSTM': 4.870277245363573, 'Transformer': 4.570919076924017, 'GNN': 4.852611974811553}
[PREDICT] Intermediate ensemble Top6: [2, 5, 7, 8, 28, 35] -> written to predicted_tickets.txt
[RUN] {"type": "predict_log", "ts": "2025-11-22T18:18:35+00:00", "hmmlearn": "0.3.3", "blend_weights": [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], "calibration": {"type": "_PostRankIsotonic", "alpha": null, "K": null}, "per_expert_pl_nll": {"Bayes": 21.85728314328339, "Markov": 22.04870616326204, "HMM": 21.982761829446005, "LSTM": 21.77282132149362, "Transformer": 23.768003330902687, "GNN": 21.70765519948999}, "weekday_gate": null, "feedback": {"window": 90, "t_fit": 748, "brier": 0.1431215855655981, "logloss": 0.5751281453347421}}
[DIAG] Backtest summary: {'type': 'backtest_summary', 'ts': '2025-11-22T18:25:20+00:00', 'n_evals': 150, 'avg_main_pl_nll': 21.739812172559716, 'avg_top6_recall': 0.14333333333333334, 'hit_any_rate': 0.6266666666666667}
[DIAG] Oracle ablation mean ΔNLL: {'Bayes': 4.421498378402405, 'Markov': 4.420462563624899, 'HMM': 4.419795528494259, 'LSTM': 4.418692406072063, 'Transformer': 4.416972421899243, 'GNN': 4.41977008629326}
[FINAL] Prediction written to predicted_tickets.txt: (4, 9, 14, 16, 30, 38)
[RUN] {"type": "predict_log", "ts": "2025-11-22T18:56:40+00:00", "hmmlearn": "0.3.3", "blend_weights": [null], "calibration": {"type": "_PostRankIsotonic", "alpha": null, "K": null, "best_beta": 1.0}, "per_expert_pl_nll": {"Bayes": 21.85728314328339, "Markov": 22.04870616326204, "HMM": 21.982761829446005, "LSTM": 21.76365463368284, "Transformer": 22.28315965736371, "GNN": 21.70765519948999}, "weekday_gate": null, "feedback": {"window": 90, "t_fit": 748, "brier": 0.1431215855655981, "logloss": 0.5751281453347421}}
[FINAL] Method=Ensemble6+BayesFallback  ticket=(4, 9, 14, 16, 30, 38)  metrics={'avg_hits': 0.0, 'mean_nll': 16.932042580950096}
